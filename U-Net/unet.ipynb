{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "unet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2BxCNFnlNA6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54a7d6df-4963-413e-b79b-2ebb2f339d00"
      },
      "source": [
        "# -*- coding:utf-8 -*-\n",
        "# DeepGlobe Images\n",
        "\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "\n",
        "class dataProcess(object):\n",
        "  def __init__(self, out_rows, out_cols, data_path=\"/content/drive/My Drive/codalab/satellite_images\", label_path=\"/content/drive/My Drive/codalab/masks\", \n",
        "               test_path=\"/content/drive/My Drive/codalab/test/sat\", npy_path=\"/content/drive/My Drive/codalab/npydata\", img_type=\"jpg\"):\n",
        "    self.out_rows = out_rows\n",
        "    self.out_cols = out_cols\n",
        "    self.data_path = data_path\n",
        "    self.label_path = label_path\n",
        "    self.img_type = img_type\n",
        "    self.test_path = test_path\n",
        "    self.npy_path = npy_path\n",
        "\n",
        "  def create_train_data(self):\n",
        "    i = 0\n",
        "    print('Creating training images...')\n",
        "    imgs = glob.glob(self.data_path+\"/*.\"+self.img_type)\n",
        "    labels = glob.glob(self.label_path+\"/*.\"+self.img_type)\n",
        "    imgdatas = np.ndarray((len(imgs), self.out_rows, self.out_cols, 3), dtype=np.uint8)\n",
        "    imglabels = np.ndarray((len(imgs), self.out_rows, self.out_cols, 1), dtype=np.uint8)\n",
        "\n",
        "    for x in range(len(imgs)):\n",
        "      imgpath = imgs[x]\n",
        "      #print('imgpath: ', imgpath)\n",
        "      #labelpath_img = labels[x]\n",
        "      pic_name = imgpath.split('/')[-1]\n",
        "      #print(pic_name)\n",
        "      #label_name = labelpath_img.split('/')[-1]\n",
        "      labelpath = self.label_path + '/' + pic_name\n",
        "      img = load_img(imgpath, target_size=[256, 256])\n",
        "      label = load_img(labelpath, color_mode=\"grayscale\", target_size=[256, 256])\n",
        "      img = img_to_array(img)\n",
        "      label = img_to_array(label)\n",
        "      imgdatas[i] = img\n",
        "      imglabels[i] = label\n",
        "      if i % 100 == 0:\n",
        "        print('Done: {0}/{1} images'.format(i, len(imgs)))\n",
        "      i += 1\n",
        "\n",
        "    print('loading done')\n",
        "    np.save(self.npy_path + '/imgs_train.npy', imgdatas)\n",
        "    np.save(self.npy_path + '/imgs_mask_train.npy', imglabels)\n",
        "    print('Saving to .npy files done.')\n",
        "\n",
        "  def create_test_data(self):\n",
        "    i = 0\n",
        "    print('Creating test images...')\n",
        "    imgs = glob.glob(self.test_path + \"/*.\" + self.img_type)\n",
        "    imgdatas = np.ndarray((len(imgs), self.out_rows, self.out_cols, 3), dtype=np.uint8)\n",
        "    testpathlist = []\n",
        "\n",
        "    for imgname in imgs:\n",
        "      testpath = imgname\n",
        "      testpathlist.append(testpath)\n",
        "      img = load_img(testpath, target_size=[256, 256]) #grayscale=False,\n",
        "      img = img_to_array(img)\n",
        "      imgdatas[i] = img\n",
        "      i += 1\n",
        "\n",
        "    txtname = '/content/drive/My Drive/codalab/unet_results/pic.txt'\n",
        "    with open(txtname, 'w') as f:\n",
        "      for i in range(len(testpathlist)):\n",
        "        f.writelines(testpathlist[i] + '\\n')\n",
        "    print('loading done')\n",
        "    np.save(self.npy_path + '/imgs_test.npy', imgdatas)\n",
        "    print('Saving to imgs_test.npy files done.')\n",
        "\n",
        "  def load_train_data(self):\n",
        "    print('load train images...')\n",
        "    imgs_train = np.load(self.npy_path + \"/imgs_train.npy\")\n",
        "    imgs_mask_train = np.load(self.npy_path + \"/imgs_mask_train.npy\")\n",
        "    imgs_train = imgs_train.astype('float32')\n",
        "    imgs_mask_train = imgs_mask_train.astype('float32')\n",
        "    imgs_train /= 255.\n",
        "    imgs_mask_train /= 255.\n",
        "    imgs_mask_train[imgs_mask_train > 0.5] = 1  \n",
        "    imgs_mask_train[imgs_mask_train <= 0.5] = 0 \n",
        "    return imgs_train, imgs_mask_train\n",
        "\n",
        "  def load_test_data(self):\n",
        "    print('-' * 30)\n",
        "    print('load test images...')\n",
        "    print('-' * 30)\n",
        "    imgs_test = np.load(self.npy_path + \"/imgs_test.npy\")\n",
        "    imgs_test = imgs_test.astype('float32')\n",
        "    imgs_test /= 255.\n",
        "    return imgs_test\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    mydata = dataProcess(256, 256)\n",
        "    mydata.create_train_data()\n",
        "    mydata.create_test_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating training images...\n",
            "Done: 0/500 images\n",
            "Done: 100/500 images\n",
            "Done: 200/500 images\n",
            "Done: 300/500 images\n",
            "Done: 400/500 images\n",
            "loading done\n",
            "Saving to .npy files done.\n",
            "Creating test images...\n",
            "loading done\n",
            "Saving to imgs_test.npy files done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shm6cQeGe2B9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11cf6a63-f9ea-473d-994f-b628441de973"
      },
      "source": [
        "# -*- coding:utf-8 -*-\n",
        "\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.image import array_to_img\n",
        "import cv2\n",
        "#from data import *\n",
        "\n",
        "\n",
        "class myUnet(object):\n",
        "  def __init__(self, img_rows=256, img_cols=256):\n",
        "    self.img_rows = img_rows\n",
        "    self.img_cols = img_cols\n",
        "\n",
        "  def load_data(self):\n",
        "    mydata = dataProcess(self.img_rows, self.img_cols)\n",
        "    imgs_train, imgs_mask_train = mydata.load_train_data()\n",
        "    imgs_test = mydata.load_test_data()\n",
        "    return imgs_train, imgs_mask_train, imgs_test\n",
        "\n",
        "  def get_unet(self):\n",
        "    inputs = Input((self.img_rows, self.img_cols, 3))\n",
        "\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
        "    # print(conv1)\n",
        "    print(\"conv1 shape:\", conv1.shape)\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
        "    print(\"conv1 shape:\", conv1.shape)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    print(\"pool1 shape:\", pool1.shape)\n",
        "\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
        "    print(\"conv2 shape:\", conv2.shape)\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
        "    print(\"conv2 shape:\", conv2.shape)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    print(\"pool2 shape:\", pool2.shape)\n",
        "\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
        "    print(\"conv3 shape:\", conv3.shape)\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
        "    print(\"conv3 shape:\", conv3.shape)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    print(\"pool3 shape:\", pool3.shape)\n",
        "\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "    print(\"drop4 shape:\", drop4.shape)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "    up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(drop5))\n",
        "    print(\"up6 shape:\", up6.shape)\n",
        "    merge6 = concatenate([drop4, up6], axis=3)\n",
        "    print(up6)\n",
        "    print(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
        "    print(conv6)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
        "    print(conv6)\n",
        "    up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv6))\n",
        "    merge7 = concatenate([conv3, up7], axis=3)\n",
        "    print(up7)\n",
        "    print(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
        "    print(conv7)\n",
        "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
        "    print(conv7)\n",
        "    up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv7))\n",
        "    merge8 = concatenate([conv2, up8], axis=3)\n",
        "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
        "\n",
        "    up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv8))\n",
        "    merge9 = concatenate([conv1, up9], axis=3)\n",
        "    print(up9)\n",
        "    print(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
        "    print(conv9)\n",
        "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
        "    print(conv9)\n",
        "    conv9 = Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
        "    print(\"conv9 shape:\", conv9.shape)\n",
        "\n",
        "    conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
        "    print(conv10)\n",
        "    model = Model(inputs=inputs, outputs=conv10)\n",
        "\n",
        "    model.compile(optimizer=Adam(lr=2e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "  def train(self):\n",
        "    print(\"loading data\")\n",
        "    imgs_train, imgs_mask_train, imgs_test = self.load_data()\n",
        "    print(\"loading data done\")\n",
        "    model = self.get_unet()\n",
        "    print(\"got unet\")\n",
        "    model_checkpoint = ModelCheckpoint('unet.hdf5', monitor='loss', verbose=1, save_best_only=True)\n",
        "    print('Fitting model...')\n",
        "    model.fit(imgs_train, imgs_mask_train, batch_size=1, epochs=100, verbose=1, validation_split=0.2, shuffle=True, callbacks=[model_checkpoint])\n",
        "\n",
        "    print('predict test data')\n",
        "    imgs_mask_test = model.predict(imgs_test, batch_size=1, verbose=1)\n",
        "    np.save('/content/drive/My Drive/codalab/unet_results/imgs_mask_test.npy', imgs_mask_test)\n",
        "\n",
        "  def save_img(self):\n",
        "    print(\"array to image\")\n",
        "    imgs = np.load('/content/drive/My Drive/codalab/unet_results/imgs_mask_test.npy')\n",
        "    piclist = []\n",
        "    for line in open(\"/content/drive/My Drive/codalab/unet_results/pic.txt\"):\n",
        "      line = line.strip()\n",
        "      picname = line.split('/')[-1]\n",
        "      piclist.append(picname)\n",
        "    for i in range(imgs.shape[0]):\n",
        "      path = \"/content/drive/My Drive/codalab/unet_results/\" + piclist[i]\n",
        "      img = imgs[i]\n",
        "      img = array_to_img(img)\n",
        "      img.save(path)\n",
        "      cv_pic = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "      #cv_pic = cv2.resize(cv_pic,(256,256),interpolation=cv2.INTER_CUBIC)\n",
        "      binary, cv_save = cv2.threshold(cv_pic, 127, 255, cv2.THRESH_BINARY)\n",
        "      cv2.imwrite(path, cv_save)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    myunet = myUnet()\n",
        "    model = myunet.get_unet()\n",
        "    # model.summary()\n",
        "    # plot_model(model, to_file='model.png')\n",
        "    myunet.train()\n",
        "    myunet.save_img()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1 shape: (None, 256, 256, 64)\n",
            "conv1 shape: (None, 256, 256, 64)\n",
            "pool1 shape: (None, 128, 128, 64)\n",
            "conv2 shape: (None, 128, 128, 128)\n",
            "conv2 shape: (None, 128, 128, 128)\n",
            "pool2 shape: (None, 64, 64, 128)\n",
            "conv3 shape: (None, 64, 64, 256)\n",
            "conv3 shape: (None, 64, 64, 256)\n",
            "pool3 shape: (None, 32, 32, 256)\n",
            "drop4 shape: (None, 32, 32, 512)\n",
            "up6 shape: (None, 32, 32, 512)\n",
            "Tensor(\"conv2d_10/Relu:0\", shape=(None, 32, 32, 512), dtype=float32)\n",
            "Tensor(\"concatenate/concat:0\", shape=(None, 32, 32, 1024), dtype=float32)\n",
            "Tensor(\"conv2d_11/Relu:0\", shape=(None, 32, 32, 512), dtype=float32)\n",
            "Tensor(\"conv2d_12/Relu:0\", shape=(None, 32, 32, 512), dtype=float32)\n",
            "Tensor(\"conv2d_13/Relu:0\", shape=(None, 64, 64, 256), dtype=float32)\n",
            "Tensor(\"concatenate_1/concat:0\", shape=(None, 64, 64, 512), dtype=float32)\n",
            "Tensor(\"conv2d_14/Relu:0\", shape=(None, 64, 64, 256), dtype=float32)\n",
            "Tensor(\"conv2d_15/Relu:0\", shape=(None, 64, 64, 256), dtype=float32)\n",
            "Tensor(\"conv2d_19/Relu:0\", shape=(None, 256, 256, 64), dtype=float32)\n",
            "Tensor(\"concatenate_3/concat:0\", shape=(None, 256, 256, 128), dtype=float32)\n",
            "Tensor(\"conv2d_20/Relu:0\", shape=(None, 256, 256, 64), dtype=float32)\n",
            "Tensor(\"conv2d_21/Relu:0\", shape=(None, 256, 256, 64), dtype=float32)\n",
            "conv9 shape: (None, 256, 256, 2)\n",
            "Tensor(\"conv2d_23/Sigmoid:0\", shape=(None, 256, 256, 1), dtype=float32)\n",
            "loading data\n",
            "load train images...\n",
            "------------------------------\n",
            "load test images...\n",
            "------------------------------\n",
            "loading data done\n",
            "conv1 shape: (None, 256, 256, 64)\n",
            "conv1 shape: (None, 256, 256, 64)\n",
            "pool1 shape: (None, 128, 128, 64)\n",
            "conv2 shape: (None, 128, 128, 128)\n",
            "conv2 shape: (None, 128, 128, 128)\n",
            "pool2 shape: (None, 64, 64, 128)\n",
            "conv3 shape: (None, 64, 64, 256)\n",
            "conv3 shape: (None, 64, 64, 256)\n",
            "pool3 shape: (None, 32, 32, 256)\n",
            "drop4 shape: (None, 32, 32, 512)\n",
            "up6 shape: (None, 32, 32, 512)\n",
            "Tensor(\"conv2d_34/Relu:0\", shape=(None, 32, 32, 512), dtype=float32)\n",
            "Tensor(\"concatenate_4/concat:0\", shape=(None, 32, 32, 1024), dtype=float32)\n",
            "Tensor(\"conv2d_35/Relu:0\", shape=(None, 32, 32, 512), dtype=float32)\n",
            "Tensor(\"conv2d_36/Relu:0\", shape=(None, 32, 32, 512), dtype=float32)\n",
            "Tensor(\"conv2d_37/Relu:0\", shape=(None, 64, 64, 256), dtype=float32)\n",
            "Tensor(\"concatenate_5/concat:0\", shape=(None, 64, 64, 512), dtype=float32)\n",
            "Tensor(\"conv2d_38/Relu:0\", shape=(None, 64, 64, 256), dtype=float32)\n",
            "Tensor(\"conv2d_39/Relu:0\", shape=(None, 64, 64, 256), dtype=float32)\n",
            "Tensor(\"conv2d_43/Relu:0\", shape=(None, 256, 256, 64), dtype=float32)\n",
            "Tensor(\"concatenate_7/concat:0\", shape=(None, 256, 256, 128), dtype=float32)\n",
            "Tensor(\"conv2d_44/Relu:0\", shape=(None, 256, 256, 64), dtype=float32)\n",
            "Tensor(\"conv2d_45/Relu:0\", shape=(None, 256, 256, 64), dtype=float32)\n",
            "conv9 shape: (None, 256, 256, 2)\n",
            "Tensor(\"conv2d_47/Sigmoid:0\", shape=(None, 256, 256, 1), dtype=float32)\n",
            "got unet\n",
            "Fitting model...\n",
            "Epoch 1/100\n",
            "  2/400 [..............................] - ETA: 12s - loss: 1.4863 - accuracy: 0.8732WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0224s vs `on_train_batch_end` time: 0.0385s). Check your callbacks.\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.3949 - accuracy: 0.8660WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0032s vs `on_test_batch_end` time: 0.0138s). Check your callbacks.\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.39494, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 65ms/step - loss: 0.3949 - accuracy: 0.8660 - val_loss: 0.3537 - val_accuracy: 0.8715\n",
            "Epoch 2/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.3415 - accuracy: 0.8693\n",
            "Epoch 00002: loss improved from 0.39494 to 0.34151, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.3415 - accuracy: 0.8693 - val_loss: 0.3180 - val_accuracy: 0.8767\n",
            "Epoch 3/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.3086 - accuracy: 0.8772\n",
            "Epoch 00003: loss improved from 0.34151 to 0.30855, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.3086 - accuracy: 0.8772 - val_loss: 0.2977 - val_accuracy: 0.8849\n",
            "Epoch 4/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.2893 - accuracy: 0.8842\n",
            "Epoch 00004: loss improved from 0.30855 to 0.28933, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.2893 - accuracy: 0.8842 - val_loss: 0.2752 - val_accuracy: 0.8891\n",
            "Epoch 5/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.2682 - accuracy: 0.8919\n",
            "Epoch 00005: loss improved from 0.28933 to 0.26820, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.2682 - accuracy: 0.8919 - val_loss: 0.2675 - val_accuracy: 0.8928\n",
            "Epoch 6/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.2565 - accuracy: 0.8974\n",
            "Epoch 00006: loss improved from 0.26820 to 0.25654, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.2565 - accuracy: 0.8974 - val_loss: 0.2435 - val_accuracy: 0.9018\n",
            "Epoch 7/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.2417 - accuracy: 0.9030\n",
            "Epoch 00007: loss improved from 0.25654 to 0.24169, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.2417 - accuracy: 0.9030 - val_loss: 0.2304 - val_accuracy: 0.9077\n",
            "Epoch 8/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.2254 - accuracy: 0.9092\n",
            "Epoch 00008: loss improved from 0.24169 to 0.22537, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.2254 - accuracy: 0.9092 - val_loss: 0.2324 - val_accuracy: 0.9044\n",
            "Epoch 9/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.2132 - accuracy: 0.9139\n",
            "Epoch 00009: loss improved from 0.22537 to 0.21321, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.2132 - accuracy: 0.9139 - val_loss: 0.2239 - val_accuracy: 0.9107\n",
            "Epoch 10/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.2163 - accuracy: 0.9127\n",
            "Epoch 00010: loss did not improve from 0.21321\n",
            "400/400 [==============================] - 24s 61ms/step - loss: 0.2163 - accuracy: 0.9127 - val_loss: 0.2250 - val_accuracy: 0.9118\n",
            "Epoch 11/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.1942 - accuracy: 0.9216\n",
            "Epoch 00011: loss improved from 0.21321 to 0.19419, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.1942 - accuracy: 0.9216 - val_loss: 0.2168 - val_accuracy: 0.9137\n",
            "Epoch 12/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.1803 - accuracy: 0.9269\n",
            "Epoch 00012: loss improved from 0.19419 to 0.18034, saving model to unet.hdf5\n",
            "400/400 [==============================] - 25s 64ms/step - loss: 0.1803 - accuracy: 0.9269 - val_loss: 0.2291 - val_accuracy: 0.9058\n",
            "Epoch 13/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.1686 - accuracy: 0.9315\n",
            "Epoch 00013: loss improved from 0.18034 to 0.16861, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 65ms/step - loss: 0.1686 - accuracy: 0.9315 - val_loss: 0.2171 - val_accuracy: 0.9139\n",
            "Epoch 14/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.1559 - accuracy: 0.9363\n",
            "Epoch 00014: loss improved from 0.16861 to 0.15589, saving model to unet.hdf5\n",
            "400/400 [==============================] - 25s 64ms/step - loss: 0.1559 - accuracy: 0.9363 - val_loss: 0.2145 - val_accuracy: 0.9155\n",
            "Epoch 15/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.1473 - accuracy: 0.9393\n",
            "Epoch 00015: loss improved from 0.15589 to 0.14733, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.1473 - accuracy: 0.9393 - val_loss: 0.2192 - val_accuracy: 0.9108\n",
            "Epoch 16/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.1328 - accuracy: 0.9452\n",
            "Epoch 00016: loss improved from 0.14733 to 0.13283, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.1328 - accuracy: 0.9452 - val_loss: 0.2293 - val_accuracy: 0.9164\n",
            "Epoch 17/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.1234 - accuracy: 0.9487\n",
            "Epoch 00017: loss improved from 0.13283 to 0.12338, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.1234 - accuracy: 0.9487 - val_loss: 0.2330 - val_accuracy: 0.9109\n",
            "Epoch 18/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.1151 - accuracy: 0.9517\n",
            "Epoch 00018: loss improved from 0.12338 to 0.11509, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 65ms/step - loss: 0.1151 - accuracy: 0.9517 - val_loss: 0.2359 - val_accuracy: 0.9155\n",
            "Epoch 19/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.1066 - accuracy: 0.9551\n",
            "Epoch 00019: loss improved from 0.11509 to 0.10658, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 66ms/step - loss: 0.1066 - accuracy: 0.9551 - val_loss: 0.2350 - val_accuracy: 0.9151\n",
            "Epoch 20/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0974 - accuracy: 0.9588\n",
            "Epoch 00020: loss improved from 0.10658 to 0.09744, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0974 - accuracy: 0.9588 - val_loss: 0.2606 - val_accuracy: 0.9175\n",
            "Epoch 21/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0924 - accuracy: 0.9609\n",
            "Epoch 00021: loss improved from 0.09744 to 0.09242, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0924 - accuracy: 0.9609 - val_loss: 0.2742 - val_accuracy: 0.9158\n",
            "Epoch 22/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0882 - accuracy: 0.9626\n",
            "Epoch 00022: loss improved from 0.09242 to 0.08821, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0882 - accuracy: 0.9626 - val_loss: 0.2847 - val_accuracy: 0.9179\n",
            "Epoch 23/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0829 - accuracy: 0.9647\n",
            "Epoch 00023: loss improved from 0.08821 to 0.08294, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0829 - accuracy: 0.9647 - val_loss: 0.2680 - val_accuracy: 0.9172\n",
            "Epoch 24/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0752 - accuracy: 0.9679\n",
            "Epoch 00024: loss improved from 0.08294 to 0.07518, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0752 - accuracy: 0.9679 - val_loss: 0.2759 - val_accuracy: 0.9167\n",
            "Epoch 25/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0737 - accuracy: 0.9686\n",
            "Epoch 00025: loss improved from 0.07518 to 0.07373, saving model to unet.hdf5\n",
            "400/400 [==============================] - 25s 64ms/step - loss: 0.0737 - accuracy: 0.9686 - val_loss: 0.2818 - val_accuracy: 0.9170\n",
            "Epoch 26/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0699 - accuracy: 0.9702\n",
            "Epoch 00026: loss improved from 0.07373 to 0.06994, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0699 - accuracy: 0.9702 - val_loss: 0.3055 - val_accuracy: 0.9150\n",
            "Epoch 27/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0679 - accuracy: 0.9711\n",
            "Epoch 00027: loss improved from 0.06994 to 0.06790, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0679 - accuracy: 0.9711 - val_loss: 0.3072 - val_accuracy: 0.9166\n",
            "Epoch 28/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.9730\n",
            "Epoch 00028: loss improved from 0.06790 to 0.06316, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0632 - accuracy: 0.9730 - val_loss: 0.3045 - val_accuracy: 0.9151\n",
            "Epoch 29/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 0.9747\n",
            "Epoch 00029: loss improved from 0.06316 to 0.05930, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0593 - accuracy: 0.9747 - val_loss: 0.3658 - val_accuracy: 0.9195\n",
            "Epoch 30/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0594 - accuracy: 0.9747\n",
            "Epoch 00030: loss did not improve from 0.05930\n",
            "400/400 [==============================] - 24s 61ms/step - loss: 0.0594 - accuracy: 0.9747 - val_loss: 0.3496 - val_accuracy: 0.9185\n",
            "Epoch 31/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.9753\n",
            "Epoch 00031: loss improved from 0.05930 to 0.05812, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0581 - accuracy: 0.9753 - val_loss: 0.3283 - val_accuracy: 0.9170\n",
            "Epoch 32/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 0.9764\n",
            "Epoch 00032: loss improved from 0.05812 to 0.05554, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0555 - accuracy: 0.9764 - val_loss: 0.3659 - val_accuracy: 0.9180\n",
            "Epoch 33/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0532 - accuracy: 0.9774\n",
            "Epoch 00033: loss improved from 0.05554 to 0.05316, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0532 - accuracy: 0.9774 - val_loss: 0.3220 - val_accuracy: 0.9144\n",
            "Epoch 34/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0522 - accuracy: 0.9778\n",
            "Epoch 00034: loss improved from 0.05316 to 0.05225, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0522 - accuracy: 0.9778 - val_loss: 0.3716 - val_accuracy: 0.9192\n",
            "Epoch 35/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0508 - accuracy: 0.9784\n",
            "Epoch 00035: loss improved from 0.05225 to 0.05083, saving model to unet.hdf5\n",
            "400/400 [==============================] - 25s 63ms/step - loss: 0.0508 - accuracy: 0.9784 - val_loss: 0.3515 - val_accuracy: 0.9184\n",
            "Epoch 36/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 0.9796\n",
            "Epoch 00036: loss improved from 0.05083 to 0.04803, saving model to unet.hdf5\n",
            "400/400 [==============================] - 25s 63ms/step - loss: 0.0480 - accuracy: 0.9796 - val_loss: 0.3605 - val_accuracy: 0.9197\n",
            "Epoch 37/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0464 - accuracy: 0.9803\n",
            "Epoch 00037: loss improved from 0.04803 to 0.04635, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0464 - accuracy: 0.9803 - val_loss: 0.3768 - val_accuracy: 0.9177\n",
            "Epoch 38/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0454 - accuracy: 0.9807\n",
            "Epoch 00038: loss improved from 0.04635 to 0.04543, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0454 - accuracy: 0.9807 - val_loss: 0.3571 - val_accuracy: 0.9157\n",
            "Epoch 39/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.9804\n",
            "Epoch 00039: loss did not improve from 0.04543\n",
            "400/400 [==============================] - 24s 61ms/step - loss: 0.0461 - accuracy: 0.9804 - val_loss: 0.3878 - val_accuracy: 0.9175\n",
            "Epoch 40/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 0.9813\n",
            "Epoch 00040: loss improved from 0.04543 to 0.04395, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0440 - accuracy: 0.9813 - val_loss: 0.4408 - val_accuracy: 0.9204\n",
            "Epoch 41/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0427 - accuracy: 0.9819\n",
            "Epoch 00041: loss improved from 0.04395 to 0.04272, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0427 - accuracy: 0.9819 - val_loss: 0.4076 - val_accuracy: 0.9142\n",
            "Epoch 42/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0439 - accuracy: 0.9814\n",
            "Epoch 00042: loss did not improve from 0.04272\n",
            "400/400 [==============================] - 24s 61ms/step - loss: 0.0439 - accuracy: 0.9814 - val_loss: 0.3539 - val_accuracy: 0.9177\n",
            "Epoch 43/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 0.9827\n",
            "Epoch 00043: loss improved from 0.04272 to 0.04090, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0409 - accuracy: 0.9827 - val_loss: 0.3943 - val_accuracy: 0.9178\n",
            "Epoch 44/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0416 - accuracy: 0.9824\n",
            "Epoch 00044: loss did not improve from 0.04090\n",
            "400/400 [==============================] - 24s 61ms/step - loss: 0.0416 - accuracy: 0.9824 - val_loss: 0.3766 - val_accuracy: 0.9172\n",
            "Epoch 45/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.9834\n",
            "Epoch 00045: loss improved from 0.04090 to 0.03918, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0392 - accuracy: 0.9834 - val_loss: 0.4230 - val_accuracy: 0.9185\n",
            "Epoch 46/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0389 - accuracy: 0.9835\n",
            "Epoch 00046: loss improved from 0.03918 to 0.03887, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0389 - accuracy: 0.9835 - val_loss: 0.4552 - val_accuracy: 0.9194\n",
            "Epoch 47/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 0.9837\n",
            "Epoch 00047: loss improved from 0.03887 to 0.03862, saving model to unet.hdf5\n",
            "400/400 [==============================] - 25s 64ms/step - loss: 0.0386 - accuracy: 0.9837 - val_loss: 0.4398 - val_accuracy: 0.9197\n",
            "Epoch 48/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9844\n",
            "Epoch 00048: loss improved from 0.03862 to 0.03693, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0369 - accuracy: 0.9844 - val_loss: 0.4116 - val_accuracy: 0.9189\n",
            "Epoch 49/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9844\n",
            "Epoch 00049: loss improved from 0.03693 to 0.03692, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0369 - accuracy: 0.9844 - val_loss: 0.3641 - val_accuracy: 0.9169\n",
            "Epoch 50/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0356 - accuracy: 0.9850\n",
            "Epoch 00050: loss improved from 0.03692 to 0.03562, saving model to unet.hdf5\n",
            "400/400 [==============================] - 25s 63ms/step - loss: 0.0356 - accuracy: 0.9850 - val_loss: 0.4267 - val_accuracy: 0.9198\n",
            "Epoch 51/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 0.9855\n",
            "Epoch 00051: loss improved from 0.03562 to 0.03426, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0343 - accuracy: 0.9855 - val_loss: 0.4226 - val_accuracy: 0.9174\n",
            "Epoch 52/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.9849\n",
            "Epoch 00052: loss did not improve from 0.03426\n",
            "400/400 [==============================] - 25s 61ms/step - loss: 0.0358 - accuracy: 0.9849 - val_loss: 0.4796 - val_accuracy: 0.9213\n",
            "Epoch 53/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0339 - accuracy: 0.9857\n",
            "Epoch 00053: loss improved from 0.03426 to 0.03390, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0339 - accuracy: 0.9857 - val_loss: 0.4140 - val_accuracy: 0.9188\n",
            "Epoch 54/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.9856\n",
            "Epoch 00054: loss did not improve from 0.03390\n",
            "400/400 [==============================] - 24s 61ms/step - loss: 0.0342 - accuracy: 0.9856 - val_loss: 0.4806 - val_accuracy: 0.9195\n",
            "Epoch 55/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 0.9858\n",
            "Epoch 00055: loss improved from 0.03390 to 0.03361, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0336 - accuracy: 0.9858 - val_loss: 0.4584 - val_accuracy: 0.9199\n",
            "Epoch 56/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 0.9868\n",
            "Epoch 00056: loss improved from 0.03361 to 0.03142, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0314 - accuracy: 0.9868 - val_loss: 0.4962 - val_accuracy: 0.9210\n",
            "Epoch 57/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9869\n",
            "Epoch 00057: loss improved from 0.03142 to 0.03118, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0312 - accuracy: 0.9869 - val_loss: 0.4650 - val_accuracy: 0.9201\n",
            "Epoch 58/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 0.9867\n",
            "Epoch 00058: loss did not improve from 0.03118\n",
            "400/400 [==============================] - 24s 61ms/step - loss: 0.0317 - accuracy: 0.9867 - val_loss: 0.4690 - val_accuracy: 0.9202\n",
            "Epoch 59/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 0.9870\n",
            "Epoch 00059: loss improved from 0.03118 to 0.03085, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0308 - accuracy: 0.9870 - val_loss: 0.4765 - val_accuracy: 0.9191\n",
            "Epoch 60/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0300 - accuracy: 0.9874\n",
            "Epoch 00060: loss improved from 0.03085 to 0.02997, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0300 - accuracy: 0.9874 - val_loss: 0.4845 - val_accuracy: 0.9189\n",
            "Epoch 61/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.9869\n",
            "Epoch 00061: loss did not improve from 0.02997\n",
            "400/400 [==============================] - 24s 61ms/step - loss: 0.0311 - accuracy: 0.9869 - val_loss: 0.4884 - val_accuracy: 0.9205\n",
            "Epoch 62/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 0.9876\n",
            "Epoch 00062: loss improved from 0.02997 to 0.02950, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0295 - accuracy: 0.9876 - val_loss: 0.4812 - val_accuracy: 0.9202\n",
            "Epoch 63/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 0.9880\n",
            "Epoch 00063: loss improved from 0.02950 to 0.02851, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0285 - accuracy: 0.9880 - val_loss: 0.4875 - val_accuracy: 0.9200\n",
            "Epoch 64/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0281 - accuracy: 0.9882\n",
            "Epoch 00064: loss improved from 0.02851 to 0.02806, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0281 - accuracy: 0.9882 - val_loss: 0.5014 - val_accuracy: 0.9200\n",
            "Epoch 65/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0293 - accuracy: 0.9877\n",
            "Epoch 00065: loss did not improve from 0.02806\n",
            "400/400 [==============================] - 24s 61ms/step - loss: 0.0293 - accuracy: 0.9877 - val_loss: 0.4878 - val_accuracy: 0.9192\n",
            "Epoch 66/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 0.9879\n",
            "Epoch 00066: loss did not improve from 0.02806\n",
            "400/400 [==============================] - 24s 61ms/step - loss: 0.0289 - accuracy: 0.9879 - val_loss: 0.4947 - val_accuracy: 0.9203\n",
            "Epoch 67/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0280 - accuracy: 0.9883\n",
            "Epoch 00067: loss improved from 0.02806 to 0.02800, saving model to unet.hdf5\n",
            "400/400 [==============================] - 25s 64ms/step - loss: 0.0280 - accuracy: 0.9883 - val_loss: 0.4729 - val_accuracy: 0.9181\n",
            "Epoch 68/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0273 - accuracy: 0.9886\n",
            "Epoch 00068: loss improved from 0.02800 to 0.02731, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 65ms/step - loss: 0.0273 - accuracy: 0.9886 - val_loss: 0.4991 - val_accuracy: 0.9195\n",
            "Epoch 69/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 0.9886\n",
            "Epoch 00069: loss improved from 0.02731 to 0.02724, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 65ms/step - loss: 0.0272 - accuracy: 0.9886 - val_loss: 0.4912 - val_accuracy: 0.9189\n",
            "Epoch 70/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 0.9887\n",
            "Epoch 00070: loss improved from 0.02724 to 0.02696, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 65ms/step - loss: 0.0270 - accuracy: 0.9887 - val_loss: 0.5035 - val_accuracy: 0.9208\n",
            "Epoch 71/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 0.9891\n",
            "Epoch 00071: loss improved from 0.02696 to 0.02616, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0262 - accuracy: 0.9891 - val_loss: 0.5281 - val_accuracy: 0.9207\n",
            "Epoch 72/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9892\n",
            "Epoch 00072: loss improved from 0.02616 to 0.02574, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0257 - accuracy: 0.9892 - val_loss: 0.5185 - val_accuracy: 0.9204\n",
            "Epoch 73/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.9894\n",
            "Epoch 00073: loss improved from 0.02574 to 0.02542, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0254 - accuracy: 0.9894 - val_loss: 0.5322 - val_accuracy: 0.9212\n",
            "Epoch 74/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9897\n",
            "Epoch 00074: loss improved from 0.02542 to 0.02473, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0247 - accuracy: 0.9897 - val_loss: 0.5279 - val_accuracy: 0.9204\n",
            "Epoch 75/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9896\n",
            "Epoch 00075: loss improved from 0.02473 to 0.02471, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0247 - accuracy: 0.9896 - val_loss: 0.5006 - val_accuracy: 0.9187\n",
            "Epoch 76/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.9894\n",
            "Epoch 00076: loss did not improve from 0.02471\n",
            "400/400 [==============================] - 25s 61ms/step - loss: 0.0254 - accuracy: 0.9894 - val_loss: 0.5219 - val_accuracy: 0.9204\n",
            "Epoch 77/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9897\n",
            "Epoch 00077: loss did not improve from 0.02471\n",
            "400/400 [==============================] - 25s 61ms/step - loss: 0.0247 - accuracy: 0.9897 - val_loss: 0.4860 - val_accuracy: 0.9188\n",
            "Epoch 78/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9897\n",
            "Epoch 00078: loss improved from 0.02471 to 0.02468, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0247 - accuracy: 0.9897 - val_loss: 0.5199 - val_accuracy: 0.9197\n",
            "Epoch 79/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9902\n",
            "Epoch 00079: loss improved from 0.02468 to 0.02352, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 65ms/step - loss: 0.0235 - accuracy: 0.9902 - val_loss: 0.5637 - val_accuracy: 0.9208\n",
            "Epoch 80/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 0.9900\n",
            "Epoch 00080: loss did not improve from 0.02352\n",
            "400/400 [==============================] - 25s 63ms/step - loss: 0.0241 - accuracy: 0.9900 - val_loss: 0.4795 - val_accuracy: 0.9182\n",
            "Epoch 81/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9900\n",
            "Epoch 00081: loss did not improve from 0.02352\n",
            "400/400 [==============================] - 25s 62ms/step - loss: 0.0240 - accuracy: 0.9900 - val_loss: 0.5329 - val_accuracy: 0.9197\n",
            "Epoch 82/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 0.9904\n",
            "Epoch 00082: loss improved from 0.02352 to 0.02312, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0231 - accuracy: 0.9904 - val_loss: 0.5511 - val_accuracy: 0.9194\n",
            "Epoch 83/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 0.9908\n",
            "Epoch 00083: loss improved from 0.02312 to 0.02211, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0221 - accuracy: 0.9908 - val_loss: 0.5789 - val_accuracy: 0.9207\n",
            "Epoch 84/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9908\n",
            "Epoch 00084: loss improved from 0.02211 to 0.02205, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0220 - accuracy: 0.9908 - val_loss: 0.5550 - val_accuracy: 0.9199\n",
            "Epoch 85/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9902\n",
            "Epoch 00085: loss did not improve from 0.02205\n",
            "400/400 [==============================] - 24s 61ms/step - loss: 0.0236 - accuracy: 0.9902 - val_loss: 0.5676 - val_accuracy: 0.9210\n",
            "Epoch 86/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 0.9906\n",
            "Epoch 00086: loss did not improve from 0.02205\n",
            "400/400 [==============================] - 25s 61ms/step - loss: 0.0226 - accuracy: 0.9906 - val_loss: 0.5468 - val_accuracy: 0.9206\n",
            "Epoch 87/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9912\n",
            "Epoch 00087: loss improved from 0.02205 to 0.02127, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 66ms/step - loss: 0.0213 - accuracy: 0.9912 - val_loss: 0.5434 - val_accuracy: 0.9183\n",
            "Epoch 88/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9914\n",
            "Epoch 00088: loss improved from 0.02127 to 0.02080, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0208 - accuracy: 0.9914 - val_loss: 0.5442 - val_accuracy: 0.9208\n",
            "Epoch 89/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 0.9907\n",
            "Epoch 00089: loss did not improve from 0.02080\n",
            "400/400 [==============================] - 25s 62ms/step - loss: 0.0223 - accuracy: 0.9907 - val_loss: 0.5466 - val_accuracy: 0.9202\n",
            "Epoch 90/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0217 - accuracy: 0.9910\n",
            "Epoch 00090: loss did not improve from 0.02080\n",
            "400/400 [==============================] - 25s 62ms/step - loss: 0.0217 - accuracy: 0.9910 - val_loss: 0.5522 - val_accuracy: 0.9202\n",
            "Epoch 91/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9912\n",
            "Epoch 00091: loss did not improve from 0.02080\n",
            "400/400 [==============================] - 25s 62ms/step - loss: 0.0213 - accuracy: 0.9912 - val_loss: 0.5856 - val_accuracy: 0.9212\n",
            "Epoch 92/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9913\n",
            "Epoch 00092: loss did not improve from 0.02080\n",
            "400/400 [==============================] - 24s 61ms/step - loss: 0.0209 - accuracy: 0.9913 - val_loss: 0.6197 - val_accuracy: 0.9218\n",
            "Epoch 93/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9919\n",
            "Epoch 00093: loss improved from 0.02080 to 0.01959, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0196 - accuracy: 0.9919 - val_loss: 0.5989 - val_accuracy: 0.9202\n",
            "Epoch 94/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9920\n",
            "Epoch 00094: loss improved from 0.01959 to 0.01936, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 64ms/step - loss: 0.0194 - accuracy: 0.9920 - val_loss: 0.6051 - val_accuracy: 0.9217\n",
            "Epoch 95/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 0.9914\n",
            "Epoch 00095: loss did not improve from 0.01936\n",
            "400/400 [==============================] - 24s 61ms/step - loss: 0.0207 - accuracy: 0.9914 - val_loss: 0.5581 - val_accuracy: 0.9209\n",
            "Epoch 96/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9913\n",
            "Epoch 00096: loss did not improve from 0.01936\n",
            "400/400 [==============================] - 24s 61ms/step - loss: 0.0211 - accuracy: 0.9913 - val_loss: 0.5283 - val_accuracy: 0.9197\n",
            "Epoch 97/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 0.9915\n",
            "Epoch 00097: loss did not improve from 0.01936\n",
            "400/400 [==============================] - 24s 61ms/step - loss: 0.0206 - accuracy: 0.9915 - val_loss: 0.6160 - val_accuracy: 0.9215\n",
            "Epoch 98/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.9922\n",
            "Epoch 00098: loss improved from 0.01936 to 0.01901, saving model to unet.hdf5\n",
            "400/400 [==============================] - 25s 64ms/step - loss: 0.0190 - accuracy: 0.9922 - val_loss: 0.5684 - val_accuracy: 0.9197\n",
            "Epoch 99/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9922\n",
            "Epoch 00099: loss improved from 0.01901 to 0.01879, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 65ms/step - loss: 0.0188 - accuracy: 0.9922 - val_loss: 0.5747 - val_accuracy: 0.9205\n",
            "Epoch 100/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9925\n",
            "Epoch 00100: loss improved from 0.01879 to 0.01828, saving model to unet.hdf5\n",
            "400/400 [==============================] - 26s 66ms/step - loss: 0.0183 - accuracy: 0.9925 - val_loss: 0.5885 - val_accuracy: 0.9204\n",
            "predict test data\n",
            " 1/50 [..............................] - ETA: 0sWARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0047s vs `on_predict_batch_end` time: 0.0137s). Check your callbacks.\n",
            "50/50 [==============================] - 1s 18ms/step\n",
            "array to image\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIFOS47__h69"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}